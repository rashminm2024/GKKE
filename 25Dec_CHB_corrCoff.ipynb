{"cells":[{"cell_type":"markdown","metadata":{"id":"4n4ZDahyzFBb"},"source":["*   **Dataset**: CHB\n","*   **Processing**: corelation coefficient\n","\n","*   **Epochs**: 30  preictal+ictal\n","*   **Kernels**: WL, Spectral Decomposition, Random Walk\n","*   **Classifiers**: Decision Tree, Random Forest, SVC\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46784,"status":"ok","timestamp":1735360355944,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"uInNiN2HD9gw","outputId":"80b1a6cb-cb82-49ca-b657-c662f3fb5cf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mne\n","  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n","Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n","Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.8.0)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.2)\n","Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.67.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.12.14)\n","Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mne\n","Successfully installed mne-1.9.0\n","Collecting graphkit-learn\n","  Downloading graphkit_learn-0.2.1.post20240206154638-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (1.13.1)\n","Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (3.8.0)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (3.4.2)\n","Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (1.6.0)\n","Requirement already satisfied: tabulate>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (0.9.0)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (4.67.1)\n","Collecting control>=0.8.2 (from graphkit-learn)\n","  Downloading control-0.10.1-py3-none-any.whl.metadata (7.6 kB)\n","Requirement already satisfied: cvxopt>=1.2.5 in /usr/local/lib/python3.10/dist-packages (from graphkit-learn) (1.3.2)\n","Collecting mosek>=9.2.5 (from graphkit-learn)\n","  Downloading Mosek-10.2.12-cp37-abi3-manylinux2014_x86_64.whl.metadata (698 bytes)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.0->graphkit-learn) (2.8.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->graphkit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1.0->graphkit-learn) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.0->graphkit-learn) (1.17.0)\n","Downloading graphkit_learn-0.2.1.post20240206154638-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.3/386.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading control-0.10.1-py3-none-any.whl (549 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.6/549.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Mosek-10.2.12-cp37-abi3-manylinux2014_x86_64.whl (15.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mosek, control, graphkit-learn\n","Successfully installed control-0.10.1 graphkit-learn-0.2.1.post20240206154638 mosek-10.2.12\n"]}],"source":["!pip install mne\n","!pip install graphkit-learn\n","\n","import numpy as np\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import mne\n","\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","\n","from os import listdir\n","from os.path import isfile, join\n","import tqdm\n","import multiprocessing\n","import networkx as nx\n","from collections import Counter, defaultdict\n","#from grakel.kernels import RandomWalk\n","from gklearn.utils.kernels import deltakernel, gaussiankernel, kernelproduct\n","import functools\n","from multiprocessing.pool import ThreadPool as Pool\n","\n","from sklearn.decomposition import PCA,KernelPCA\n","\n","import scipy.signal as sig\n","from scipy import linalg, stats\n","import seaborn as sns\n","\n","\n","import datetime\n","timestamp = datetime.datetime.now()\n","timestamp = timestamp.timestamp() * 1000\n","timestamp = str(timestamp)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwgdfeC6EkTv","executionInfo":{"status":"ok","timestamp":1735360393228,"user_tz":240,"elapsed":19736,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"}},"outputId":"ec09eeb3-0f51-4b23-bd80-f2ee7af755ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import os\n","os.chdir(\"drive/My Drive/Journal_Executions\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41067,"status":"ok","timestamp":1735362157453,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"6d17qZ27et2P","outputId":"c772de8f-31bf-495c-c2c7-2d475a9e2ccb","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["f Data_EDF/chb02\n","f ['Data_EDF', 'chb02']\n","p chb02\n","f Data_EDF/chb02\n","p Data_EDF/chb02/chb02-summary.txt\n","215\n","3 4\n","Reading 0 ... 245503  =      0.000 ...   958.996 secs...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:135: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.7s\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.2s\n"]},{"output_type":"stream","name":"stdout","text":["Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:135: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.5s\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    2.7s\n"]},{"output_type":"stream","name":"stdout","text":["Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:135: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.5s\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    3.8s\n"]},{"output_type":"stream","name":"stdout","text":["Reading 0 ... 245503  =      0.000 ...   958.996 secs...\n","Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n","Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.7s\n","[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.7s\n"]},{"output_type":"stream","name":"stdout","text":["Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.5s\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    2.7s\n"]},{"output_type":"stream","name":"stdout","text":["Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.5s\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    4.3s\n"]},{"output_type":"stream","name":"stdout","text":["Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-29-022773aa6cfa>:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n","  raw = mne.io.read_raw_edf(f, verbose=False)\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 50 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 50.00 Hz\n","- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n","- Filter length: 69 samples (0.270 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    1.5s\n"]},{"output_type":"stream","name":"stdout","text":["Filtering raw data in 1 contiguous segment\n","Setting up low-pass filter at 1e+02 Hz\n","\n","FIR filter parameters\n","---------------------\n","Designing a one-pass, zero-phase, non-causal lowpass filter:\n","- Windowed time-domain design (firwin) method\n","- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n","- Upper passband edge: 100.00 Hz\n","- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n","- Filter length: 35 samples (0.137 s)\n","\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    2.6s\n"]},{"output_type":"stream","name":"stdout","text":["Ictal:  (22, 44032) \n","Preictal:  (22, 921600)\n","Preictal epochs: 1800 \n"," (1800, 22, 512)\n","Ictal epochs: 86 \n"," (86, 22, 512)\n"]}],"source":["#Repeat for CHB data\n","# fpath=['/content/gdrive/MyDrive/ProjectData/chb02']\n","# fpath=\"C:\\\\Users\\\\Owner\\\\OneDrive - University of New Brunswick\\\\Thesis\\\\Code\\\\graphKKE\\\\mPLV\\\\Data_EDF\\\\chb02\"\n","\n","ictalfp=[];ictalf=[];seizest=[];seizen=[];\n","preictalfp=[];preictalf=[];preseizest=[];preseizen=[];\n","interictalfp=[];interictalf=[];interseizest=[];interseizen=[];\n","\n","SPH = [0,20]\n","SPHl = SPH[0]*60;\n","SPHu = SPH[1]*60;\n","ch=[0, 22];\n","MINSPHu=SPH[0];\n","MAXSPHl=SPH[1];\n","\n","fpath = ['Data_EDF/chb02']\n","\n","for f in fpath:\n","    print('f', f)\n","    print('f', f.split('/'))\n","    p=f.split('/')[-1]\n","    print('p', p)\n","    print('f', f)\n","    f1=f+'/'+p+'-summary.txt'\n","    print('p', f1)\n","    f2 = open(f1,'r+')\n","    string_list=f2.readlines()\n","    print(len(string_list))\n","    i=0;#flag=0\n","    fs = string_list[0].split()[-2]\n","    while (string_list[i][0]!='F'):\n","        i=i+1\n","    while (i<len(string_list)): #(flag!=1):\n","        if (string_list[i+3][len(string_list[i+3])-2]=='0'):\n","              i=i+5\n","        else:\n","            d=string_list[i].split(); ictal_fname= d[2]\n","            d=string_list[i+4].split(); st_t = int(d[3])\n","            d=string_list[i+5].split(); en_t = int(d[3])\n","\n","          #CREATE ICTAL LIST\n","            ictalfp.append(f+'/'+ictal_fname);\n","            ictalf.append(ictal_fname);\n","            seizest.append(st_t);seizen.append(en_t)\n","\n","          #CREATE PREICTAL as SPHu min = SPHu*60 sec before and upto the seizure start point if available,\n","          # else include from previous file\n","\n","            if (st_t-SPHu>=0):\n","                pst=st_t-SPHu; pen=st_t-SPHl;\n","                preictalfp.append(f+'/'+ictal_fname);preictalf.append(ictal_fname);preseizest.append(pst);preseizen.append(pen)\n","\n","            #ADD REMAINING FRONT DATA TO INTERICTAL\n","                if (st_t-SPHu >0):\n","                    intst=0; inten=st_t-SPHu; #DATA BEFORE PREICTAL\n","                    interictalfp.append(f+'/'+ictal_fname);interictalf.append(ictal_fname);interseizest.append(intst);interseizen.append(inten)\n","                #ADD REMAINING TAIL DATA TO INTERICTAL IF NEXT FILE IS NON-SEIZURE FILE\n","                if (string_list[i+10][len(string_list[i+3])-2]=='0'):\n","                    intst=int(en_t); inten=3600;#DATA AFTER SEIZURE END UPTO END of FILE\n","                    interictalfp.append(f+'/'+ictal_fname);interictalf.append(ictal_fname);interseizest.append(intst);interseizen.append(inten)\n","\n","            else:\n","                #IF SUFFICIENT (30 min) PREICTAL DATA NOT AVAILABLE IN THE CURRENT FILE THEN PICK FROM CURRENT FILE and FROM PREVIOUS FILE IF AVAILABLE\n","                pst=0;  pen=st_t-SPHl;\n","                preictalfp.append(f+'/'+ictal_fname);preictalf.append(ictal_fname);preseizest.append(pst);preseizen.append(pen)\n","                remainlength =SPHu-st_t\n","                #IF PREVIOUS FILE IS NON-SEIZURE FILE PICK REMAINING secs without any further CHECK\n","\n","                if (string_list[i-2][len(string_list[i+3])-2]=='0'):\n","                    d=string_list[i-5].split(); preictal_fname= d[2] #NAME OF PREVIOUS FILE\n","                    pst=3600-remainlength;  pen=3600; #Assuming each file MITPHYSIONET having 60 min recording- to be customized for other set-up\n","                    preictalfp.append(f+'/'+preictal_fname);preictalf.append(preictal_fname);preseizest.append(pst);preseizen.append(pen)\n","\n","                      #ADD REMAINING FRONT DATA OF PREVIOUS NON SEIZURE FILE TO INTERICTAL\n","                    intst=0; inten=pst-1;#DATA BEFORE PREICTAL\n","                    interictalfp.append(f+'/'+preictal_fname);interictalf.append(preictal_fname);interseizest.append(intst);interseizen.append(inten)\n","\n","                      #ADD REMAINING  DATA OF PREVIOUS ALL NON SEIZURE FILES TO INTERICTAL\n","                    j=i-7 #Last line of file preceding previous file\n","                    while(string_list[j][len(string_list[j])-2]=='0'): #will carry 0 only if it is Non-Seizure file\n","                        d=string_list[j-3].split(); interictal_fname= d[2] #NAME OF NON-SEIZURE FILE\n","                        intst=0; inten=3600;#ENTIRE DATA AS INTERICTAL\n","                        interictalfp.append(f+'/'+interictal_fname);interictalf.append(interictal_fname);interseizest.append(intst);interseizen.append(inten)\n","                        j=j-5\n","\n","                else:\n","                  #OTHERWISE PICK FROM PREVIOUS (SEIZURE) FILE IF SUFFICIENT LENGTH AFTER SEIZURE END AVAILABLE-\n","                    d=string_list[i-7].split(); preictal_fname= d[2] #NAME OF PREVIOUS FILE\n","                    d=string_list[i-2].split(); enprev = int(d[3]) # #get seizure end time of previous file\n","                    available=3600-enprev\n","                    if (available >= remainlength):\n","                        pst=3600-remainlength;  pen=3600;\n","                        preictalfp.append(f+'/'+preictal_fname);preictalf.append(preictal_fname);preseizest.append(pst);preseizen.append(pen)\n","\n","                        #ADD REMAINING DATA OF PREVIOUS SEIZURE FILE TO INTERICTAL\n","                        if (pst>enprev+1):\n","                            intst=enprev+1; inten=pst;#DATA BETWEEN SEIZURE END OF PREVIOUS FILE and THE Start of PREICTAL\n","                            interictalfp.append(f+'/'+preictal_fname);interictalf.append(preictal_fname);interseizest.append(intst);interseizen.append(inten)\n","\n","                  #IF SUFFICIENT LENGTH NOT AVAILABLE, then RECORD THE AVAILABLE LENGTH AS MINSPH\n","                    else:\n","                        pst=enprev;  pen=3600; MINSPHu= SPH[1]-remainlength+ available\n","                        preictalfp.append(f+'/'+preictal_fname);preictalf.append(preictal_fname);preseizest.append(pst);preseizen.append(pen)\n","            i=i+7\n","\n","    f2.close()\n","\n","\n","dict={'ictal_fpath':ictalfp, 'ictal_f':ictalf , 'seiz_st':seizest , 'seiz_en':seizen}\n","df = pd.DataFrame(dict)\n","#print('ICTAL\\n', df)\n","\n","dict={'Preictal_fpath':preictalfp, 'Preictal_f':preictalf , 'Preseiz_st':preseizest , 'Preseiz_en':preseizen}\n","dfpre = pd.DataFrame(dict)\n","#print('Preictal\\n',dfpre)\n","\n","print(len(df),len(dfpre))\n","\n","#===================================================================================\n","#Data Selection with  Band- Pass Filter\n","band1= [0,5]; band2=[5, 8]; band3= [8,13]; band4= [13, 21]; band5= [21, 34]; band6= [34,100]\n","\n","fs= 256; #st_f=band4[0]; en_f=band4[1];\n","st_f=0; en_f=100\n","train_data=[]; train_labels=[]\n","\n","ictald=np.empty((22,0))\n","preictald=np.empty((22,0))\n","interictald=np.empty((22,0))\n","\n","#NOW USE ABOVE DATAFRAMES AND READ FILES TO FORM EPOCHS and TRAINING SET\n","#ICTAL\n","for i in range(0,len(df)):\n","    f=df['ictal_fpath'][i]\n","    raw = mne.io.read_raw_edf(f, verbose=False)\n","    raw.load_data() ## Filtering requires the data to be loaded to the memory\n","    d=raw.filter(None, 50., fir_design='firwin')#power noise notch filter at 50Hz\n","    d=raw.copy().filter(l_freq=st_f, h_freq=en_f)\n","    st=df['seiz_st'][i]; en=df['seiz_en'][i];\n","    ictald=np.concatenate((ictald,d._data[0:22, st*fs:en*fs]), axis=1)\n","#PREICTAL\n","for i in range(0,len(dfpre)):\n","    f=dfpre['Preictal_fpath'][i]\n","    raw = mne.io.read_raw_edf(f, verbose=False)\n","    raw.load_data() ## Filtering requires the data to be loaded to the memory\n","    d=raw.filter(None, 50., fir_design='firwin') #power noise notch filter at 50Hz\n","    d=raw.copy().filter(l_freq=st_f, h_freq=en_f)\n","    st=dfpre['Preseiz_st'][i]; en=dfpre['Preseiz_en'][i];\n","    preictald=np.concatenate((preictald,d._data[0:22, st*fs:en*fs]), axis=1)\n","\n","\n","#Transform using z-score\n","from scipy import stats\n","ictald=stats.zscore(ictald, axis=1)\n","preictald=stats.zscore(preictald, axis=1)\n","\n","print('Ictal: ', ictald.shape, '\\nPreictal: ', preictald.shape)\n","\n","#Create Train Data - 2s epochs from each category with corresponding label {1-preictal, 0- interictal}\n","fs=256\n","epochsize=2*fs\n","\n","#Similarly create epochs for preictal\n","epochno =preictald.shape[1]//epochsize\n","preictalepochs = np.array(np.hsplit(preictald[:,0:epochno*epochsize],epochno ))\n","print('Preictal epochs:',epochno, '\\n', preictalepochs.shape)\n","\n","#Similarly create epochs for Ictal\n","epochno =ictald.shape[1]//epochsize\n","ictalepochs = np.array(np.hsplit(ictald[:,0:epochno*epochsize],epochno ))\n","print('Ictal epochs:',epochno, '\\n', ictalepochs.shape)\n","\n"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1735367221323,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"Ib2FhBgUgfjw","outputId":"4a99515c-4f1a-42d5-d9fb-f4885506f571"},"outputs":[{"output_type":"stream","name":"stdout","text":["(60, 22, 22)\n"]}],"source":["fs=256\n","num_channels=preictalepochs.shape[1]\n","\n","nanct=0\n","NEpoch=30\n","\n","adj_matrix = np.zeros((NEpoch*2, num_channels, num_channels))\n","labels=np.zeros(NEpoch*2)\n","\n","k=0\n","for i in np.arange(0,NEpoch):\n","    epoch = preictalepochs[i,:,:] #channel_data[:,3*i*fs:3*(i+1)*fs]\n","    cor_mat = np.corrcoef(epoch) #replace with mPLV compPlv(epoch) #\n","    if(np.isnan(cor_mat).any()):\n","        nanct=nanct+1\n","        continue\n","    adj_matrix[k] = cor_mat\n","    labels[k]=0\n","    k=k+1\n","\n","nanct=0\n","NEpoch=30\n","\n","for i in np.arange(0,NEpoch):\n","    epoch = ictalepochs[i,:,:] #channel_data[:,3*i*fs:3*(i+1)*fs]\n","    cor_mat = np.corrcoef(epoch) #replace with mPLV compPlv(epoch) #\n","    if(np.isnan(cor_mat).any()):\n","        nanct=nanct+1\n","        continue\n","    adj_matrix[k] = cor_mat\n","    labels[k]=1\n","    k=k+1\n","\n","#Now Binarize Adjacency matrices before feeding for graph preparation\n","for i in np.arange(0,k):\n","    th=np.percentile(adj_matrix[i].flatten(),25)\n","    adj_matrix[i][adj_matrix[i]<th]=0\n","    adj_matrix[i][adj_matrix[i]>=th]=1\n","\n","print(adj_matrix.shape)\n","adj_matrix= adj_matrix.astype(int)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1735367221539,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"nDy34e46LV6j","outputId":"480023c5-3dd4-4005-8715-3c80d81b150d"},"outputs":[{"output_type":"stream","name":"stdout","text":["labels:::: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n","adj_matrix:::: (60, 22, 22)\n","shuffle_indices:::: [22 57 55 19 37 14 46 12  6 20 58 30 23 16 42 10 52 56 47 25 43 18 21 54\n"," 41 53 59 48 35  8  7 27 50  4 32 51  1 15 36 40  5 26 11 31 44 49 29 38\n"," 39 45  9 34 17  3 13 33  2 24  0 28]\n","labels:::: [0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1.\n"," 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1.\n"," 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n","adj_matrix:::: (60, 22, 22)\n"]}],"source":["# Generate shuffle indices for the first axis\n","\n","print('labels::::', labels)\n","print('adj_matrix::::', adj_matrix.shape)\n","shuffle_indices = np.random.permutation(adj_matrix.shape[0])\n","\n","print('shuffle_indices::::', shuffle_indices)\n","# Shuffle the array along the first axis using the generated indices\n","adj_matrix = adj_matrix[shuffle_indices]\n","labels = labels[shuffle_indices]\n","\n","print('labels::::', labels)\n","print('adj_matrix::::', adj_matrix.shape)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"elapsed":386,"status":"ok","timestamp":1735374730550,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"TfAK1vQRRbbB","outputId":"ebf8831d-1443-418a-92b4-449213a74f1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," --- Weisfeiler-Lehman subtree kernel matrix of size 60 built in 0.09592866897583008 seconds ---\n"]},{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom gklearn.kernels import SpectralDecomposition\\ngraph_kernel = SpectralDecomposition(\\n    ds_infos=graphs,\\n    weight=1e-2,\\n    p=None,\\n    q=None,\\n    edge_weight=None,\\n    sub_kernel='geo'\\n)\\nkernel = 'SD'\\nkernel_matrix = graph_kernel.compute(\\n    graphs,\\n    parallel=None,\\n    n_jobs=multiprocessing.cpu_count(),\\n    verbose=True\\n)\\n\\nfrom gklearn.kernels.randomWalkKernel import randomwalkkernel\\nfrom gklearn.utils.kernels import deltakernel, gaussiankernel, kernelproduct\\nimport functools\\nimport multiprocessing\\n\\nkernel = 'RW'\\nmixkernel = functools.partial(kernelproduct, deltakernel, gaussiankernel)\\nsub_kernels = [{'symb': deltakernel, 'nsymb': gaussiankernel, 'mix': mixkernel}]\\nsub_kernel = ['geo', 'exp']\\ncompute_method = 'conjugate'\\n\\nkernel = 'RandomWalk'\\nkernel_matrix = randomwalkkernel(\\n\\t\\t\\tgraphs,\\n\\t\\t\\tcompute_method=compute_method,\\n\\t\\t\\tweight=0.001,\\n\\t\\t\\tp=None,\\n\\t\\t\\tq=None,\\n\\t\\t\\tedge_weight=None,\\n\\t\\t\\tnode_kernels=sub_kernels,\\n\\t\\t\\tedge_kernels=sub_kernels,\\n\\t\\t\\tnode_label='atom',\\n\\t\\t\\tedge_label='bond_type',\\n\\t\\t\\tsub_kernel=sub_kernel,\\n\\t\\t\\tn_jobs=multiprocessing.cpu_count(),\\n\\t\\t\\tverbose=True\\n\\t\\t)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":67}],"source":["#adj_matrix = np.random.randint(0, 100, size=(20, 20, 20))#datafile\n","#adj_matrix computed above\n","num_nodes = adj_matrix.shape[0]\n","node_labels = list(range(1, num_nodes+1))\n","graphs = []\n","\n","for graph in adj_matrix:\n","    graph = nx.from_numpy_array(graph)\n","    mapping = {i: label for i, label in enumerate(node_labels)}\n","    graph = nx.relabel_nodes(graph, mapping)\n","    graphs.append(graph)\n","\n","from gklearn.kernels.weisfeilerLehmanKernel import weisfeilerlehmankernel\n","kernel_matrix = weisfeilerlehmankernel(\n","    graphs,\n","    node_label='atom',\n","    edge_label='bond_type',\n","    height=2,\n","    base_kernel='subtree',\n","    parallel=None,\n","    n_jobs=None,\n","    verbose=True)\n","kernel = 'WL'\n","\n","'''\n","from gklearn.kernels import SpectralDecomposition\n","graph_kernel = SpectralDecomposition(\n","    ds_infos=graphs,\n","    weight=1e-2,\n","    p=None,\n","    q=None,\n","    edge_weight=None,\n","    sub_kernel='geo'\n",")\n","kernel = 'SD'\n","kernel_matrix = graph_kernel.compute(\n","    graphs,\n","    parallel=None,\n","    n_jobs=multiprocessing.cpu_count(),\n","    verbose=True\n",")\n","\n","from gklearn.kernels.randomWalkKernel import randomwalkkernel\n","from gklearn.utils.kernels import deltakernel, gaussiankernel, kernelproduct\n","import functools\n","import multiprocessing\n","\n","kernel = 'RW'\n","mixkernel = functools.partial(kernelproduct, deltakernel, gaussiankernel)\n","sub_kernels = [{'symb': deltakernel, 'nsymb': gaussiankernel, 'mix': mixkernel}]\n","sub_kernel = ['geo', 'exp']\n","compute_method = 'conjugate'\n","\n","kernel = 'RandomWalk'\n","kernel_matrix = randomwalkkernel(\n","\t\t\tgraphs,\n","\t\t\tcompute_method=compute_method,\n","\t\t\tweight=0.001,\n","\t\t\tp=None,\n","\t\t\tq=None,\n","\t\t\tedge_weight=None,\n","\t\t\tnode_kernels=sub_kernels,\n","\t\t\tedge_kernels=sub_kernels,\n","\t\t\tnode_label='atom',\n","\t\t\tedge_label='bond_type',\n","\t\t\tsub_kernel=sub_kernel,\n","\t\t\tn_jobs=multiprocessing.cpu_count(),\n","\t\t\tverbose=True\n","\t\t)\n","'''"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1735374730551,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"1SxEZrBRYhEJ","outputId":"167d061f-3d30-4322-f609-0dbefc4ad975"},"outputs":[{"output_type":"stream","name":"stdout","text":["X VALUE:::::: (60, 1)\n","y VALUE:::::::::::: 60\n","Feature Variability: [0.03277778]\n","Label Distribution: (array([0., 1.]), array([30, 30]))\n","Explained Variance (All Components): [1.96666667]\n"]}],"source":["# kernel_matrix[0].min()\n","# print('X VALUE::::::', X.shape)\n","# # print('y VALUE::::::::::::', len(y))\n","\n","\n","#https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n","\n","# from sklearn.preprocessing import normalize\n","# kernel_matrix_normalized = normalize(kernel_matrix[0], axis=1)\n","\n","kpca = KernelPCA(kernel='rbf', gamma=1)\n","gram_kpca = kpca.fit_transform(kernel_matrix[0])\n","\n","X=gram_kpca\n","y=labels\n","\n","print('X VALUE::::::', X.shape)\n","print('y VALUE::::::::::::', len(y))\n","\n","print(\"Feature Variability:\", np.var(X, axis=0))\n","print(\"Label Distribution:\", np.unique(y, return_counts=True))\n","print(\"Explained Variance (All Components):\", kpca.eigenvalues_)\n","\n","# import matplotlib.pyplot as plt\n","# plt.scatter(X[:, 0], np.zeros_like(X[:, 0]), c=y, cmap='viridis')\n","# plt.colorbar()\n","# plt.title(\"Feature Distribution After Kernel PCA\")\n","# # plt.show()\n","# savefigure(plt, 'feature_distribution', kernel)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168660,"status":"ok","timestamp":1735374899203,"user":{"displayName":"Rashmi Nagawara Muralinath","userId":"17366972580637124625"},"user_tz":240},"id":"MP7iOosH_Gj5","outputId":"249f9818-c992-458a-ffd1-320b045c0e4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Kernel::: WL\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n","10 fits failed out of a total of 300.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","10 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 275, in fit\n","    raise ValueError(\n","ValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to be preprocessed.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.43777778 0.43777778        nan 0.43777778 0.43777778 0.43777778\n"," 0.56222222 0.56222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.56222222 0.56222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.56222222 0.56222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.52222222 0.50222222        nan 0.52222222 0.52222222 0.52222222\n"," 0.56222222 0.50222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.56222222 0.50222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.56222222 0.50222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.56222222 0.50222222        nan 0.56222222 0.56222222 0.56222222\n"," 0.56222222 0.50222222        nan 0.56222222 0.56222222 0.56222222]\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["best_svc SVC(C=0.01, kernel='linear', random_state=42)\n","best_rf RandomForestClassifier(class_weight='balanced', n_estimators=50, oob_score=True,\n","                       random_state=42)\n","best_dt DecisionTreeClassifier(class_weight='balanced', random_state=42)\n","Decision Tree - Accuracy: 0.2500, AUC: 0.5000, precision:0.0625,recall: 0.2500,f1: 0.1000\n","Random Forest - Accuracy: 0.2500, AUC: 0.5000, precision:0.0625,recall: 0.2500,f1: 0.1000\n","SVC - Accuracy: 0.2500, AUC: 0.5000, precision:0.0625,recall: 0.2500,f1: 0.1000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["print('Kernel:::', kernel)\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n","\n","param_grid_svc = {\n","  'C': [0.01, 0.1, 1, 10, 100],\n","  'kernel': ['linear', 'rbf', 'poly'],\n","  'gamma': ['scale', 'auto'],\n","  'class_weight': ['balanced', None]\n","}\n","\n","param_grid_rf = {\n","  'n_estimators': [50, 100, 200],\n","  'max_depth': [None, 10, 20, 30],\n","  'min_samples_split': [2, 5, 10],\n","  'max_features': ['sqrt', 'log2'],  # Number of features to consider for splits\n","  'class_weight': ['balanced', None]\n","}\n","\n","param_grid_dt = {\n","  'max_depth': [None, 10, 20, 30],\n","  'min_samples_split': [2, 5, 10],\n","  'class_weight': ['balanced', None]\n","}\n","\n","from sklearn.utils.class_weight import compute_class_weight\n","svc = SVC(class_weight='balanced', random_state=42)\n","rf = RandomForestClassifier(oob_score=True, class_weight='balanced', random_state=42)\n","dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n","\n","\n","# Perform grid search for each model\n","grid_search_svc = GridSearchCV(svc, param_grid_svc, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='accuracy', n_jobs=-1)\n","\n","# Fit the grid search\n","grid_search_svc.fit(X_train, y_train)\n","grid_search_rf.fit(X_train, y_train)\n","grid_search_dt.fit(X_train, y_train)\n","\n","# Get the best estimators\n","best_svc = grid_search_svc.best_estimator_\n","best_rf = grid_search_rf.best_estimator_\n","best_dt = grid_search_dt.best_estimator_\n","\n","print('best_svc', best_svc)\n","print('best_rf', best_rf)\n","print('best_dt', best_dt)\n","\n","# Evaluate each model and print accuracy and AUC\n","models = { 'Decision Tree': best_dt, 'Random Forest': best_rf, 'SVC': best_svc}\n","results = {}\n","\n","for name, model in models.items():\n","    y_pred = model.predict(X_test)\n","    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision= precision_score(y_test, y_pred, average='weighted')\n","    recall= recall_score(y_test, y_pred, average='weighted')\n","    f1=f1_score(y_test, y_pred, average='weighted')\n","    auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovo')\n","\n","    results[name] = {'accuracy': accuracy, 'AUC': auc_score, 'precision':precision,'recall': recall,'f1': f1}\n","    print(f\"{name} - Accuracy: {accuracy:.4f}, AUC: {auc_score:.4f}, precision:{precision:.4f},recall: {recall:.4f},f1: {f1:.4f}\")\n","\n","# Plot ROC Curves\n","# plt.figure(figsize=(10, 8))\n","\n","# for name, model in models.items():\n","#     y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n","#     fpr, tpr, _ = roc_curve(y_test, y_pred_proba, pos_label=1)\n","#     roc_auc = auc(fpr, tpr)\n","#     plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.2f})')\n","\n"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}